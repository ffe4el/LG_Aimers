{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = ['T050304', 'T050307', 'T100304', 'T100306', 'T010306', 'T010305']\n",
    "\n",
    "\n",
    "def seperate_code():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    output_dir = \"Input/\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "\n",
    "    for line in lines:\n",
    "        df_line = df[df[\"LINE\"] == line]\n",
    "        df_line = df_line.dropna(how=\"any\", axis=\"columns\")\n",
    "\n",
    "        # 모든 값이 동일한 열 제거\n",
    "        cols = df_line.columns[6:]\n",
    "        for col in cols:\n",
    "            if len(df_line[col].unique()) == 1:\n",
    "                df_line = df_line.drop([col], axis=1)\n",
    "\n",
    "        df_line.to_csv(os.path.join(output_dir, f\"{line}.csv\"), index=False)\n",
    "\n",
    "\n",
    "seperate_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[Index(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE',\n        'PRODUCT_CODE', 'X_128', 'X_129', 'X_136', 'X_137',\n        ...\n        'X_2796', 'X_2797', 'X_2798', 'X_2799', 'X_2800', 'X_2801', 'X_2837',\n        'X_2839', 'X_2840', 'X_2841'],\n       dtype='object', length=301),\n Index(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE',\n        'PRODUCT_CODE', 'X_130', 'X_136', 'X_137', 'X_138',\n        ...\n        'X_2796', 'X_2797', 'X_2798', 'X_2799', 'X_2800', 'X_2801', 'X_2837',\n        'X_2839', 'X_2840', 'X_2841'],\n       dtype='object', length=630),\n Index(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE',\n        'PRODUCT_CODE', 'X_1', 'X_2', 'X_5', 'X_11',\n        ...\n        'X_773', 'X_774', 'X_775', 'X_883', 'X_884', 'X_885', 'X_898', 'X_899',\n        'X_900', 'X_901'],\n       dtype='object', length=120),\n Index(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE',\n        'PRODUCT_CODE', 'X_1', 'X_2', 'X_7', 'X_8',\n        ...\n        'X_897', 'X_898', 'X_899', 'X_900', 'X_901', 'X_902', 'X_903', 'X_904',\n        'X_905', 'X_932'],\n       dtype='object', length=347),\n Index(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE',\n        'PRODUCT_CODE', 'X_246', 'X_247', 'X_248', 'X_250',\n        ...\n        'X_1696', 'X_1697', 'X_2044', 'X_2045', 'X_2046', 'X_2047', 'X_2048',\n        'X_2049', 'X_2050', 'X_2051'],\n       dtype='object', length=463),\n Index(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP', 'LINE',\n        'PRODUCT_CODE', 'X_246', 'X_247', 'X_251', 'X_253',\n        ...\n        'X_1696', 'X_1697', 'X_2044', 'X_2045', 'X_2046', 'X_2047', 'X_2048',\n        'X_2049', 'X_2050', 'X_2051'],\n       dtype='object', length=451)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_duplicate_col():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "    df = df.round(0)\n",
    "\n",
    "    drop_cols = []\n",
    "    for line in lines:\n",
    "        df_line = df[df[\"LINE\"] == line]\n",
    "        df_line = df_line.dropna(how=\"any\", axis=\"columns\")\n",
    "\n",
    "        df_line = df_line.loc[:, ~df.T.duplicated()]\n",
    "\n",
    "        cols = df_line.columns[6:]\n",
    "        for col in cols:\n",
    "            if len(df_line[col].unique()) == 1:\n",
    "                df_line = df_line.drop([col], axis=1)\n",
    "\n",
    "        drop_cols.append(df_line.columns)\n",
    "\n",
    "    return drop_cols\n",
    "\n",
    "\n",
    "find_duplicate_col()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(['X_1099',\n  'X_1109',\n  'X_1112',\n  'X_1527',\n  'X_1140',\n  'X_1104',\n  'X_2050',\n  'X_956',\n  'X_1154',\n  'X_1134',\n  'X_1530',\n  'X_1223',\n  'X_1406',\n  'X_1106',\n  'X_1152',\n  'X_1153',\n  'X_1552',\n  'X_1542',\n  'X_1078',\n  'X_1094',\n  'X_1101',\n  'X_1543',\n  'X_1107',\n  'X_1215',\n  'X_1125',\n  'X_1193',\n  'X_1227',\n  'X_1521',\n  'X_1133',\n  'X_1121',\n  'X_1090',\n  'X_1197',\n  'X_1143',\n  'X_1091',\n  'X_1136',\n  'X_1217',\n  'X_1128',\n  'X_1213',\n  'X_1086',\n  'X_2048',\n  'X_1210',\n  'X_1088',\n  'X_1201',\n  'X_1212',\n  'X_1118',\n  'X_1205',\n  'X_1097',\n  'X_1156',\n  'X_1549',\n  'X_1116',\n  'X_1220',\n  'X_1149',\n  'X_2046',\n  'X_1199',\n  'X_1226',\n  'X_1079',\n  'X_1151',\n  'X_1115',\n  'X_1100',\n  'X_1221',\n  'X_1517',\n  'X_1539',\n  'X_1546',\n  'X_1329',\n  'X_1195',\n  'X_2051',\n  'X_1155',\n  'X_1084',\n  'X_1528',\n  'X_1081',\n  'X_1080',\n  'X_1110',\n  'X_1139',\n  'X_1211',\n  'X_1554',\n  'X_1131',\n  'X_1194',\n  'X_1544',\n  'X_1202',\n  'X_1093',\n  'X_1122',\n  'X_1222',\n  'X_2049',\n  'X_1148',\n  'X_1098',\n  'X_1208',\n  'X_1553',\n  'X_1204',\n  'X_1083',\n  'X_1135',\n  'X_1124',\n  'X_1214',\n  'X_1085',\n  'X_1526',\n  'X_1142',\n  'X_1117',\n  'X_1077',\n  'X_1541',\n  'X_955',\n  'X_1203',\n  'X_1545',\n  'X_1108',\n  'X_1138',\n  'X_1547',\n  'X_1127',\n  'X_1196',\n  'X_1548',\n  'X_1089',\n  'X_1129',\n  'X_1095',\n  'X_1207',\n  'X_1550',\n  'X_1113',\n  'X_1218',\n  'X_1111',\n  'X_1126',\n  'X_1002',\n  'X_1082',\n  'X_1551',\n  'X_1147',\n  'X_1102',\n  'X_1224',\n  'X_1225',\n  'X_2047',\n  'X_1538',\n  'X_1145',\n  'X_444',\n  'X_61',\n  'X_60',\n  'X_754',\n  'X_651',\n  'X_461',\n  'X_468',\n  'X_756',\n  'X_22',\n  'X_442',\n  'X_448',\n  'X_64',\n  'X_539',\n  'X_54',\n  'X_90',\n  'X_772',\n  'X_120',\n  'X_13',\n  'X_59',\n  'X_63',\n  'X_450',\n  'X_123',\n  'X_564',\n  'X_48',\n  'X_471',\n  'X_40',\n  'X_402',\n  'X_763',\n  'X_121',\n  'X_774',\n  'X_883',\n  'X_898',\n  'X_58',\n  'X_405',\n  'X_458',\n  'X_454',\n  'X_543',\n  'X_544',\n  'X_562',\n  'X_538',\n  'X_758',\n  'X_1',\n  'X_884',\n  'X_65',\n  'X_537',\n  'X_464',\n  'X_52',\n  'X_55',\n  'X_46',\n  'X_404',\n  'X_446',\n  'X_757',\n  'X_766',\n  'X_403',\n  'X_765',\n  'X_44',\n  'X_20',\n  'X_401',\n  'X_900',\n  'X_462',\n  'X_12',\n  'X_56',\n  'X_452',\n  'X_536',\n  'X_775',\n  'X_753',\n  'X_66',\n  'X_899',\n  'X_770',\n  'X_563',\n  'X_49',\n  'X_2',\n  'X_39',\n  'X_443',\n  'X_767',\n  'X_16',\n  'X_470',\n  'X_460',\n  'X_47',\n  'X_566',\n  'X_885',\n  'X_41',\n  'X_545',\n  'X_698',\n  'X_451',\n  'X_773',\n  'X_901',\n  'X_755',\n  'X_21',\n  'X_11',\n  'X_463',\n  'X_456',\n  'X_51',\n  'X_53',\n  'X_768',\n  'X_43',\n  'X_542',\n  'X_771',\n  'X_18',\n  'X_62',\n  'X_57',\n  'X_560',\n  'X_50',\n  'X_457',\n  'X_447',\n  'X_400',\n  'X_565',\n  'X_769',\n  'X_559',\n  'X_42',\n  'X_453'],\n ['X_1099',\n  'X_1109',\n  'X_1112',\n  'X_1527',\n  'X_1140',\n  'X_1104',\n  'X_2050',\n  'X_956',\n  'X_1154',\n  'X_1134',\n  'X_1530',\n  'X_1223',\n  'X_1406',\n  'X_1106',\n  'X_1152',\n  'X_1153',\n  'X_1552',\n  'X_1542',\n  'X_1078',\n  'X_1094',\n  'X_1101',\n  'X_1543',\n  'X_1107',\n  'X_1215',\n  'X_1125',\n  'X_1193',\n  'X_1227',\n  'X_1521',\n  'X_1133',\n  'X_1121',\n  'X_1090',\n  'X_1197',\n  'X_1143',\n  'X_1091',\n  'X_1136',\n  'X_1217',\n  'X_1128',\n  'X_1213',\n  'X_1086',\n  'X_2048',\n  'X_1210',\n  'X_1088',\n  'X_1201',\n  'X_1212',\n  'X_1118',\n  'X_1205',\n  'X_1097',\n  'X_1156',\n  'X_1549',\n  'X_1116',\n  'X_1220',\n  'X_1149',\n  'X_2046',\n  'X_1199',\n  'X_1226',\n  'X_1079',\n  'X_1151',\n  'X_1115',\n  'X_1100',\n  'X_1221',\n  'X_1517',\n  'X_1539',\n  'X_1546',\n  'X_1329',\n  'X_1195',\n  'X_2051',\n  'X_1155',\n  'X_1084',\n  'X_1528',\n  'X_1081',\n  'X_1080',\n  'X_1110',\n  'X_1139',\n  'X_1211',\n  'X_1554',\n  'X_1131',\n  'X_1194',\n  'X_1544',\n  'X_1202',\n  'X_1093',\n  'X_1122',\n  'X_1222',\n  'X_2049',\n  'X_1148',\n  'X_1098',\n  'X_1208',\n  'X_1553',\n  'X_1204',\n  'X_1083',\n  'X_1135',\n  'X_1124',\n  'X_1214',\n  'X_1085',\n  'X_1526',\n  'X_1142',\n  'X_1117',\n  'X_1077',\n  'X_1541',\n  'X_955',\n  'X_1203',\n  'X_1545',\n  'X_1108',\n  'X_1138',\n  'X_1547',\n  'X_1127',\n  'X_1196',\n  'X_1548',\n  'X_1089',\n  'X_1129',\n  'X_1095',\n  'X_1207',\n  'X_1550',\n  'X_1113',\n  'X_1218',\n  'X_1111',\n  'X_1126',\n  'X_1002',\n  'X_1082',\n  'X_1551',\n  'X_1147',\n  'X_1102',\n  'X_1224',\n  'X_1225',\n  'X_2047',\n  'X_1538',\n  'X_1145'],\n ['X_444',\n  'X_61',\n  'X_60',\n  'X_754',\n  'X_651',\n  'X_461',\n  'X_468',\n  'X_756',\n  'X_22',\n  'X_442',\n  'X_448',\n  'X_64',\n  'X_539',\n  'X_54',\n  'X_90',\n  'X_772',\n  'X_120',\n  'X_13',\n  'X_59',\n  'X_63',\n  'X_450',\n  'X_123',\n  'X_564',\n  'X_48',\n  'X_471',\n  'X_40',\n  'X_402',\n  'X_763',\n  'X_121',\n  'X_774',\n  'X_883',\n  'X_898',\n  'X_58',\n  'X_405',\n  'X_458',\n  'X_454',\n  'X_543',\n  'X_544',\n  'X_562',\n  'X_538',\n  'X_758',\n  'X_1',\n  'X_884',\n  'X_65',\n  'X_537',\n  'X_464',\n  'X_52',\n  'X_55',\n  'X_46',\n  'X_404',\n  'X_446',\n  'X_757',\n  'X_766',\n  'X_403',\n  'X_765',\n  'X_44',\n  'X_20',\n  'X_401',\n  'X_900',\n  'X_462',\n  'X_12',\n  'X_56',\n  'X_452',\n  'X_536',\n  'X_775',\n  'X_753',\n  'X_66',\n  'X_899',\n  'X_770',\n  'X_563',\n  'X_49',\n  'X_2',\n  'X_39',\n  'X_443',\n  'X_767',\n  'X_16',\n  'X_470',\n  'X_460',\n  'X_47',\n  'X_566',\n  'X_885',\n  'X_41',\n  'X_545',\n  'X_698',\n  'X_451',\n  'X_773',\n  'X_901',\n  'X_755',\n  'X_21',\n  'X_11',\n  'X_463',\n  'X_456',\n  'X_51',\n  'X_53',\n  'X_768',\n  'X_43',\n  'X_542',\n  'X_771',\n  'X_18',\n  'X_62',\n  'X_57',\n  'X_560',\n  'X_50',\n  'X_457',\n  'X_447',\n  'X_400',\n  'X_565',\n  'X_769',\n  'X_559',\n  'X_42',\n  'X_453'])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_col():\n",
    "    col_list = []\n",
    "    for l, line in enumerate(lines):\n",
    "        df = pd.read_csv(f\"Input/{line}.csv\")\n",
    "\n",
    "        X = df[find_duplicate_col()[l]].drop([\"Y_Class\", \"Y_Quality\"], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "        X.to_csv(f\"Input/{line}.csv\", index=False)\n",
    "        col_list.append(X.columns)\n",
    "\n",
    "    # Code : A\n",
    "    A_col = list(set(col_list[0]) & set(col_list[1]) & set(col_list[4]) & set(col_list[5]))\n",
    "    # Code : T, O\n",
    "    OT_col = list(set(col_list[2]) & set(col_list[3]))\n",
    "\n",
    "    use_col = A_col + OT_col\n",
    "\n",
    "    return use_col, A_col, OT_col\n",
    "\n",
    "\n",
    "make_col()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  5  1]\n",
      " [ 5 29  5]\n",
      " [ 1  2 16]]\n",
      "A_정답률:0.747\n",
      "['X_318', 'X_367', 'X_1099', 'X_1430', 'X_368', 'X_1774', 'X_1295', 'X_287', 'X_1389', 'X_189', 'X_1053', 'X_1804', 'X_1743', 'X_1205', 'X_1197', 'X_1162', 'X_1954', 'X_1207', 'X_1560', 'X_953', 'X_959', 'X_1117', 'X_1948', 'X_248', 'X_1336', 'X_1202', 'X_1263', 'X_1949', 'X_286', 'X_258', 'X_1033', 'X_1048', 'X_1213', 'X_1376', 'X_1697', 'X_1120', 'X_1286', 'X_1108', 'X_1856', 'X_1744', 'X_1356', 'X_136', 'X_1290', 'X_345', 'X_1379', 'X_1243', 'X_999', 'X_1612', 'X_1665', 'X_1373', 'X_1390', 'X_1542', 'X_1833', 'X_1013', 'X_1109', 'X_1030', 'X_1058', 'X_1629', 'X_1643', 'X_1359', 'X_1155', 'X_1059', 'X_1428', 'X_1228', 'X_1262', 'X_1040', 'X_1231', 'X_1557', 'X_975', 'X_2050', 'X_985', 'X_1352', 'X_2063', 'X_1296', 'X_1329', 'X_976', 'X_339', 'X_977', 'X_1091', 'X_1735', 'X_2083', 'X_1124', 'X_1029', 'X_256', 'X_1176', 'X_1211', 'X_1556', 'X_1347', 'X_261', 'X_1371', 'X_993', 'X_979', 'X_1945', 'X_991', 'X_1408', 'X_1129', 'X_1636', 'X_2779', 'X_954', 'X_1564', 'X_1806', 'X_1967', 'X_271', 'X_2423', 'X_1621', 'X_949', 'X_1374', 'X_1272', 'X_1191', 'X_1183', 'X_247', 'X_1532', 'X_1380', 'X_955', 'X_1366', 'X_349', 'X_1951', 'X_2841', 'X_1265', 'X_1849', 'X_373', 'X_1289', 'X_2791', 'X_1287', 'X_996', 'X_1720', 'X_2418', 'X_1044', 'X_1423', 'X_1543', 'X_1787', 'X_1351', 'X_1075', 'X_2434', 'X_1260', 'X_1538', 'X_1212', 'X_298', 'X_242', 'X_1055', 'X_1054', 'X_1089', 'X_1414', 'X_1169', 'X_1061', 'X_1793', 'X_1518', 'X_986', 'X_1038', 'X_1215', 'X_1866', 'X_957', 'X_1276', 'X_973', 'X_1966', 'X_353', 'X_1850', 'X_1340', 'X_1616', 'X_2415', 'X_1214', 'X_967', 'X_1387', 'X_1609', 'X_1140', 'X_2097', 'X_1625', 'X_307', 'X_285', 'X_1427', 'X_2051', 'X_1569', 'X_1111', 'X_1280', 'X_1548', 'X_1100', 'X_1381', 'X_1274', 'X_1348', 'X_1098', 'X_944', 'X_1690', 'X_1139', 'X_961', 'X_994', 'X_1078', 'X_1256', 'X_1128', 'X_1955', 'X_146', 'X_2190', 'X_1521', 'X_1045', 'X_1651', 'X_1258', 'X_1194', 'X_1028', 'X_1584', 'X_1177', 'X_1018', 'X_1563', 'X_1854', 'X_960', 'X_1587', 'X_1182', 'X_1818', 'X_257', 'X_995', 'X_1110', 'X_380', 'X_364', 'X_1106', 'X_1669', 'X_1816', 'X_1121', 'X_1125', 'X_1126', 'X_1088', 'X_1082', 'X_1077', 'X_1718', 'X_1650', 'X_964', 'X_1135', 'X_1638', 'X_1072', 'X_1633', 'X_948', 'X_310', 'X_304', 'X_1153', 'X_1611', 'X_1154', 'X_1167', 'X_267', 'X_1740', 'X_1064', 'X_1862', 'X_1227', 'X_2747', 'X_1369', 'X_1370', 'X_1292', 'X_1223', 'X_1208', 'X_1257', 'X_1424', 'X_2787', 'X_1534', 'X_2041', 'X_1291', 'X_1242', 'X_1526', 'X_2753', 'X_1337', 'X_1338', 'X_1350', 'X_1341', 'X_2793', 'X_1552', 'X_1551', 'X_1421', 'X_1418', 'X_1349', 'X_2044', 'X_1353', 'X_1275', 'X_1297', 'X_2788', 'X_1358', 'X_1204', 'X_2771', 'X_1708', 'X_1076', 'X_2437', 'X_1554', 'X_1716', 'X_1429', 'X_2430', 'X_2782', 'X_1301', 'X_1422', 'X_1063', 'X_2412', 'X_2410', 'X_1083', 'X_379', 'X_1694', 'X_1114', 'X_350', 'X_354', 'X_1273', 'X_356', 'X_1118', 'X_1277', 'X_1278', 'X_1279', 'X_365', 'X_366', 'X_370', 'X_1097', 'X_1113', 'X_2750', 'X_1342', 'X_1107', 'X_1420', 'X_1288', 'X_1679', 'X_1104', 'X_1101', 'X_1686', 'X_1736', 'X_1051', 'X_2792', 'X_945', 'X_2078', 'X_939', 'X_1391', 'X_1388', 'X_2061', 'X_1821', 'X_1822', 'X_1383', 'X_984', 'X_982', 'X_981', 'X_1832', 'X_2794', 'X_1375', 'X_2843', 'X_1372', 'X_1339', 'X_1357', 'X_1355', 'X_1354', 'X_1346', 'X_1858', 'X_1345', 'X_1860', 'X_2058', 'X_2082', 'X_1000', 'X_1398', 'X_1419', 'X_1417', 'X_1416', 'X_1052', 'X_1748', 'X_1123', 'X_1415', 'X_1047', 'X_2800', 'X_2801', 'X_1757', 'X_1043', 'X_1042', 'X_2096', 'X_1036', 'X_1035', 'X_2047', 'X_1406', 'X_1026', 'X_1780', 'X_1019', 'X_1016', 'X_1002', 'X_1660', 'X_1344', 'X_1588', 'X_1171', 'X_2019', 'X_1185', 'X_1536', 'X_1217', 'X_1630', 'X_1246', 'X_1218', 'X_2701', 'X_1145', 'X_1174', 'X_306', 'X_1517', 'X_1148', 'X_2714', 'X_1963', 'X_1618', 'X_1617', 'X_1615', 'X_1170', 'X_265', 'X_1232', 'X_266', 'X_1156', 'X_1226', 'X_1225', 'X_1168', 'X_2020', 'X_1224', 'X_2715', 'X_1189', 'X_1190', 'X_142', 'X_1561', 'X_338', 'X_129', 'X_1657', 'X_344', 'X_2023', 'X_140', 'X_1553', 'X_1544', 'X_1646', 'X_138', 'X_1187', 'X_1133', 'X_1200', 'X_1188', 'X_2731']\n"
     ]
    },
    {
     "data": {
      "text/plain": "(LGBMClassifier(random_state=42),\n Index(['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10',\n        ...\n        'X_2866', 'X_2867', 'X_2868', 'X_2869', 'X_2870', 'X_2871', 'X_2872',\n        'X_2873', 'X_2874', 'X_2875'],\n       dtype='object', length=2875),\n ['X_318',\n  'X_367',\n  'X_1099',\n  'X_1430',\n  'X_368',\n  'X_1774',\n  'X_1295',\n  'X_287',\n  'X_1389',\n  'X_189',\n  'X_1053',\n  'X_1804',\n  'X_1743',\n  'X_1205',\n  'X_1197',\n  'X_1162',\n  'X_1954',\n  'X_1207',\n  'X_1560',\n  'X_953',\n  'X_959',\n  'X_1117',\n  'X_1948',\n  'X_248',\n  'X_1336',\n  'X_1202',\n  'X_1263',\n  'X_1949',\n  'X_286',\n  'X_258',\n  'X_1033',\n  'X_1048',\n  'X_1213',\n  'X_1376',\n  'X_1697',\n  'X_1120',\n  'X_1286',\n  'X_1108',\n  'X_1856',\n  'X_1744',\n  'X_1356',\n  'X_136',\n  'X_1290',\n  'X_345',\n  'X_1379',\n  'X_1243',\n  'X_999',\n  'X_1612',\n  'X_1665',\n  'X_1373',\n  'X_1390',\n  'X_1542',\n  'X_1833',\n  'X_1013',\n  'X_1109',\n  'X_1030',\n  'X_1058',\n  'X_1629',\n  'X_1643',\n  'X_1359',\n  'X_1155',\n  'X_1059',\n  'X_1428',\n  'X_1228',\n  'X_1262',\n  'X_1040',\n  'X_1231',\n  'X_1557',\n  'X_975',\n  'X_2050',\n  'X_985',\n  'X_1352',\n  'X_2063',\n  'X_1296',\n  'X_1329',\n  'X_976',\n  'X_339',\n  'X_977',\n  'X_1091',\n  'X_1735',\n  'X_2083',\n  'X_1124',\n  'X_1029',\n  'X_256',\n  'X_1176',\n  'X_1211',\n  'X_1556',\n  'X_1347',\n  'X_261',\n  'X_1371',\n  'X_993',\n  'X_979',\n  'X_1945',\n  'X_991',\n  'X_1408',\n  'X_1129',\n  'X_1636',\n  'X_2779',\n  'X_954',\n  'X_1564',\n  'X_1806',\n  'X_1967',\n  'X_271',\n  'X_2423',\n  'X_1621',\n  'X_949',\n  'X_1374',\n  'X_1272',\n  'X_1191',\n  'X_1183',\n  'X_247',\n  'X_1532',\n  'X_1380',\n  'X_955',\n  'X_1366',\n  'X_349',\n  'X_1951',\n  'X_2841',\n  'X_1265',\n  'X_1849',\n  'X_373',\n  'X_1289',\n  'X_2791',\n  'X_1287',\n  'X_996',\n  'X_1720',\n  'X_2418',\n  'X_1044',\n  'X_1423',\n  'X_1543',\n  'X_1787',\n  'X_1351',\n  'X_1075',\n  'X_2434',\n  'X_1260',\n  'X_1538',\n  'X_1212',\n  'X_298',\n  'X_242',\n  'X_1055',\n  'X_1054',\n  'X_1089',\n  'X_1414',\n  'X_1169',\n  'X_1061',\n  'X_1793',\n  'X_1518',\n  'X_986',\n  'X_1038',\n  'X_1215',\n  'X_1866',\n  'X_957',\n  'X_1276',\n  'X_973',\n  'X_1966',\n  'X_353',\n  'X_1850',\n  'X_1340',\n  'X_1616',\n  'X_2415',\n  'X_1214',\n  'X_967',\n  'X_1387',\n  'X_1609',\n  'X_1140',\n  'X_2097',\n  'X_1625',\n  'X_307',\n  'X_285',\n  'X_1427',\n  'X_2051',\n  'X_1569',\n  'X_1111',\n  'X_1280',\n  'X_1548',\n  'X_1100',\n  'X_1381',\n  'X_1274',\n  'X_1348',\n  'X_1098',\n  'X_944',\n  'X_1690',\n  'X_1139',\n  'X_961',\n  'X_994',\n  'X_1078',\n  'X_1256',\n  'X_1128',\n  'X_1955',\n  'X_146',\n  'X_2190',\n  'X_1521',\n  'X_1045',\n  'X_1651',\n  'X_1258',\n  'X_1194',\n  'X_1028',\n  'X_1584',\n  'X_1177',\n  'X_1018',\n  'X_1563',\n  'X_1854',\n  'X_960',\n  'X_1587',\n  'X_1182',\n  'X_1818',\n  'X_257',\n  'X_995',\n  'X_1110',\n  'X_380',\n  'X_364',\n  'X_1106',\n  'X_1669',\n  'X_1816',\n  'X_1121',\n  'X_1125',\n  'X_1126',\n  'X_1088',\n  'X_1082',\n  'X_1077',\n  'X_1718',\n  'X_1650',\n  'X_964',\n  'X_1135',\n  'X_1638',\n  'X_1072',\n  'X_1633',\n  'X_948',\n  'X_310',\n  'X_304',\n  'X_1153',\n  'X_1611',\n  'X_1154',\n  'X_1167',\n  'X_267',\n  'X_1740',\n  'X_1064',\n  'X_1862',\n  'X_1227',\n  'X_2747',\n  'X_1369',\n  'X_1370',\n  'X_1292',\n  'X_1223',\n  'X_1208',\n  'X_1257',\n  'X_1424',\n  'X_2787',\n  'X_1534',\n  'X_2041',\n  'X_1291',\n  'X_1242',\n  'X_1526',\n  'X_2753',\n  'X_1337',\n  'X_1338',\n  'X_1350',\n  'X_1341',\n  'X_2793',\n  'X_1552',\n  'X_1551',\n  'X_1421',\n  'X_1418',\n  'X_1349',\n  'X_2044',\n  'X_1353',\n  'X_1275',\n  'X_1297',\n  'X_2788',\n  'X_1358',\n  'X_1204',\n  'X_2771',\n  'X_1708',\n  'X_1076',\n  'X_2437',\n  'X_1554',\n  'X_1716',\n  'X_1429',\n  'X_2430',\n  'X_2782',\n  'X_1301',\n  'X_1422',\n  'X_1063',\n  'X_2412',\n  'X_2410',\n  'X_1083',\n  'X_379',\n  'X_1694',\n  'X_1114',\n  'X_350',\n  'X_354',\n  'X_1273',\n  'X_356',\n  'X_1118',\n  'X_1277',\n  'X_1278',\n  'X_1279',\n  'X_365',\n  'X_366',\n  'X_370',\n  'X_1097',\n  'X_1113',\n  'X_2750',\n  'X_1342',\n  'X_1107',\n  'X_1420',\n  'X_1288',\n  'X_1679',\n  'X_1104',\n  'X_1101',\n  'X_1686',\n  'X_1736',\n  'X_1051',\n  'X_2792',\n  'X_945',\n  'X_2078',\n  'X_939',\n  'X_1391',\n  'X_1388',\n  'X_2061',\n  'X_1821',\n  'X_1822',\n  'X_1383',\n  'X_984',\n  'X_982',\n  'X_981',\n  'X_1832',\n  'X_2794',\n  'X_1375',\n  'X_2843',\n  'X_1372',\n  'X_1339',\n  'X_1357',\n  'X_1355',\n  'X_1354',\n  'X_1346',\n  'X_1858',\n  'X_1345',\n  'X_1860',\n  'X_2058',\n  'X_2082',\n  'X_1000',\n  'X_1398',\n  'X_1419',\n  'X_1417',\n  'X_1416',\n  'X_1052',\n  'X_1748',\n  'X_1123',\n  'X_1415',\n  'X_1047',\n  'X_2800',\n  'X_2801',\n  'X_1757',\n  'X_1043',\n  'X_1042',\n  'X_2096',\n  'X_1036',\n  'X_1035',\n  'X_2047',\n  'X_1406',\n  'X_1026',\n  'X_1780',\n  'X_1019',\n  'X_1016',\n  'X_1002',\n  'X_1660',\n  'X_1344',\n  'X_1588',\n  'X_1171',\n  'X_2019',\n  'X_1185',\n  'X_1536',\n  'X_1217',\n  'X_1630',\n  'X_1246',\n  'X_1218',\n  'X_2701',\n  'X_1145',\n  'X_1174',\n  'X_306',\n  'X_1517',\n  'X_1148',\n  'X_2714',\n  'X_1963',\n  'X_1618',\n  'X_1617',\n  'X_1615',\n  'X_1170',\n  'X_265',\n  'X_1232',\n  'X_266',\n  'X_1156',\n  'X_1226',\n  'X_1225',\n  'X_1168',\n  'X_2020',\n  'X_1224',\n  'X_2715',\n  'X_1189',\n  'X_1190',\n  'X_142',\n  'X_1561',\n  'X_338',\n  'X_129',\n  'X_1657',\n  'X_344',\n  'X_2023',\n  'X_140',\n  'X_1553',\n  'X_1544',\n  'X_1646',\n  'X_138',\n  'X_1187',\n  'X_1133',\n  'X_1200',\n  'X_1188',\n  'X_2731'])"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def data_modeling_A():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "\n",
    "    data_A = df[df[\"PRODUCT_CODE\"] == \"A_31\"]\n",
    "    # data_A = data_A.fillna(0)\n",
    "    A_y = data_A[\"Y_Class\"]\n",
    "    A_X = data_A.drop([\"Y_Class\", \"Y_Quality\"], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(A_X, A_y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model_A = lgb.LGBMClassifier(random_state=42)\n",
    "    model_A.fit(X_train, y_train)\n",
    "    prediction = model_A.predict(X_test)\n",
    "\n",
    "    #특성중요도 찾기\n",
    "    feat_labels = X_train.columns\n",
    "    # result = model_A.feature_importances_\n",
    "    # print(result.importances_mean)\n",
    "    importances = model_A.feature_importances_\n",
    "    # argsort : 리스트 인덱스의 정렬됐을 때의 인덱스 값 반환, [::-1] : 뒤집기\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    a = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        if importances[indices[i]] > 0:\n",
    "            a.append(feat_labels[indices[i]])\n",
    "            # print(a)\n",
    "\n",
    "    # a=[]\n",
    "    # for i in range(100):\n",
    "    #     a.append(feat_labels[indices[i]])\n",
    "    # print(a)\n",
    "\n",
    "    print(confusion_matrix(prediction, y_test))\n",
    "    print(f\"A_정답률:{accuracy_score(prediction, y_test):.3f}\")\n",
    "\n",
    "    print(a)\n",
    "\n",
    "    return model_A, A_X.columns, a\n",
    "\n",
    "\n",
    "data_modeling_A()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  4  1]\n",
      " [ 6 28  5]\n",
      " [ 1  4 16]]\n",
      "A_정답률:0.720\n"
     ]
    },
    {
     "data": {
      "text/plain": "(LGBMClassifier(random_state=42),\n Index(['X_318', 'X_367', 'X_1099', 'X_1430', 'X_368', 'X_1774', 'X_1295',\n        'X_287', 'X_1389', 'X_189',\n        ...\n        'X_140', 'X_1553', 'X_1544', 'X_1646', 'X_138', 'X_1187', 'X_1133',\n        'X_1200', 'X_1188', 'X_2731'],\n       dtype='object', length=418))"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 318한개로 돌려보기....?\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def data_modeling_Aa():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "\n",
    "    data_A = df[df[\"PRODUCT_CODE\"] == \"A_31\"]\n",
    "    # data_A = data_A.fillna(0)\n",
    "    A_y = data_A[\"Y_Class\"]\n",
    "    A_X = data_A.drop([\"Y_Class\", \"Y_Quality\"], axis=1).select_dtypes(exclude=['object'])\n",
    "    A_X = A_X[['X_318',\n",
    "               'X_367',\n",
    "               'X_1099',\n",
    "               'X_1430',\n",
    "               'X_368',\n",
    "               'X_1774',\n",
    "               'X_1295',\n",
    "               'X_287',\n",
    "               'X_1389',\n",
    "               'X_189',\n",
    "               'X_1053',\n",
    "               'X_1804',\n",
    "               'X_1743',\n",
    "               'X_1205',\n",
    "               'X_1197',\n",
    "               'X_1162',\n",
    "               'X_1954',\n",
    "               'X_1207',\n",
    "               'X_1560',\n",
    "               'X_953',\n",
    "               'X_959',\n",
    "               'X_1117',\n",
    "               'X_1948',\n",
    "               'X_248',\n",
    "               'X_1336',\n",
    "               'X_1202',\n",
    "               'X_1263',\n",
    "               'X_1949',\n",
    "               'X_286',\n",
    "               'X_258',\n",
    "               'X_1033',\n",
    "               'X_1048',\n",
    "               'X_1213',\n",
    "               'X_1376',\n",
    "               'X_1697',\n",
    "               'X_1120',\n",
    "               'X_1286',\n",
    "               'X_1108',\n",
    "               'X_1856',\n",
    "               'X_1744',\n",
    "               'X_1356',\n",
    "               'X_136',\n",
    "               'X_1290',\n",
    "               'X_345',\n",
    "               'X_1379',\n",
    "               'X_1243',\n",
    "               'X_999',\n",
    "               'X_1612',\n",
    "               'X_1665',\n",
    "               'X_1373',\n",
    "               'X_1390',\n",
    "               'X_1542',\n",
    "               'X_1833',\n",
    "               'X_1013',\n",
    "               'X_1109',\n",
    "               'X_1030',\n",
    "               'X_1058',\n",
    "               'X_1629',\n",
    "               'X_1643',\n",
    "               'X_1359',\n",
    "               'X_1155',\n",
    "               'X_1059',\n",
    "               'X_1428',\n",
    "               'X_1228',\n",
    "               'X_1262',\n",
    "               'X_1040',\n",
    "               'X_1231',\n",
    "               'X_1557',\n",
    "               'X_975',\n",
    "               'X_2050',\n",
    "               'X_985',\n",
    "               'X_1352',\n",
    "               'X_2063',\n",
    "               'X_1296',\n",
    "               'X_1329',\n",
    "               'X_976',\n",
    "               'X_339',\n",
    "               'X_977',\n",
    "               'X_1091',\n",
    "               'X_1735',\n",
    "               'X_2083',\n",
    "               'X_1124',\n",
    "               'X_1029',\n",
    "               'X_256',\n",
    "               'X_1176',\n",
    "               'X_1211',\n",
    "               'X_1556',\n",
    "               'X_1347',\n",
    "               'X_261',\n",
    "               'X_1371',\n",
    "               'X_993',\n",
    "               'X_979',\n",
    "               'X_1945',\n",
    "               'X_991',\n",
    "               'X_1408',\n",
    "               'X_1129',\n",
    "               'X_1636',\n",
    "               'X_2779',\n",
    "               'X_954',\n",
    "               'X_1564',\n",
    "               'X_1806',\n",
    "               'X_1967',\n",
    "               'X_271',\n",
    "               'X_2423',\n",
    "               'X_1621',\n",
    "               'X_949',\n",
    "               'X_1374',\n",
    "               'X_1272',\n",
    "               'X_1191',\n",
    "               'X_1183',\n",
    "               'X_247',\n",
    "               'X_1532',\n",
    "               'X_1380',\n",
    "               'X_955',\n",
    "               'X_1366',\n",
    "               'X_349',\n",
    "               'X_1951',\n",
    "               'X_2841',\n",
    "               'X_1265',\n",
    "               'X_1849',\n",
    "               'X_373',\n",
    "               'X_1289',\n",
    "               'X_2791',\n",
    "               'X_1287',\n",
    "               'X_996',\n",
    "               'X_1720',\n",
    "               'X_2418',\n",
    "               'X_1044',\n",
    "               'X_1423',\n",
    "               'X_1543',\n",
    "               'X_1787',\n",
    "               'X_1351',\n",
    "               'X_1075',\n",
    "               'X_2434',\n",
    "               'X_1260',\n",
    "               'X_1538',\n",
    "               'X_1212',\n",
    "               'X_298',\n",
    "               'X_242',\n",
    "               'X_1055',\n",
    "               'X_1054',\n",
    "               'X_1089',\n",
    "               'X_1414',\n",
    "               'X_1169',\n",
    "               'X_1061',\n",
    "               'X_1793',\n",
    "               'X_1518',\n",
    "               'X_986',\n",
    "               'X_1038',\n",
    "               'X_1215',\n",
    "               'X_1866',\n",
    "               'X_957',\n",
    "               'X_1276',\n",
    "               'X_973',\n",
    "               'X_1966',\n",
    "               'X_353',\n",
    "               'X_1850',\n",
    "               'X_1340',\n",
    "               'X_1616',\n",
    "               'X_2415',\n",
    "               'X_1214',\n",
    "               'X_967',\n",
    "               'X_1387',\n",
    "               'X_1609',\n",
    "               'X_1140',\n",
    "               'X_2097',\n",
    "               'X_1625',\n",
    "               'X_307',\n",
    "               'X_285',\n",
    "               'X_1427',\n",
    "               'X_2051',\n",
    "               'X_1569',\n",
    "               'X_1111',\n",
    "               'X_1280',\n",
    "               'X_1548',\n",
    "               'X_1100',\n",
    "               'X_1381',\n",
    "               'X_1274',\n",
    "               'X_1348',\n",
    "               'X_1098',\n",
    "               'X_944',\n",
    "               'X_1690',\n",
    "               'X_1139',\n",
    "               'X_961',\n",
    "               'X_994',\n",
    "               'X_1078',\n",
    "               'X_1256',\n",
    "               'X_1128',\n",
    "               'X_1955',\n",
    "               'X_146',\n",
    "               'X_2190',\n",
    "               'X_1521',\n",
    "               'X_1045',\n",
    "               'X_1651',\n",
    "               'X_1258',\n",
    "               'X_1194',\n",
    "               'X_1028',\n",
    "               'X_1584',\n",
    "               'X_1177',\n",
    "               'X_1018',\n",
    "               'X_1563',\n",
    "               'X_1854',\n",
    "               'X_960',\n",
    "               'X_1587',\n",
    "               'X_1182',\n",
    "               'X_1818',\n",
    "               'X_257',\n",
    "               'X_995',\n",
    "               'X_1110',\n",
    "               'X_380',\n",
    "               'X_364',\n",
    "               'X_1106',\n",
    "               'X_1669',\n",
    "               'X_1816',\n",
    "               'X_1121',\n",
    "               'X_1125',\n",
    "               'X_1126',\n",
    "               'X_1088',\n",
    "               'X_1082',\n",
    "               'X_1077',\n",
    "               'X_1718',\n",
    "               'X_1650',\n",
    "               'X_964',\n",
    "               'X_1135',\n",
    "               'X_1638',\n",
    "               'X_1072',\n",
    "               'X_1633',\n",
    "               'X_948',\n",
    "               'X_310',\n",
    "               'X_304',\n",
    "               'X_1153',\n",
    "               'X_1611',\n",
    "               'X_1154',\n",
    "               'X_1167',\n",
    "               'X_267',\n",
    "               'X_1740',\n",
    "               'X_1064',\n",
    "               'X_1862',\n",
    "               'X_1227',\n",
    "               'X_2747',\n",
    "               'X_1369',\n",
    "               'X_1370',\n",
    "               'X_1292',\n",
    "               'X_1223',\n",
    "               'X_1208',\n",
    "               'X_1257',\n",
    "               'X_1424',\n",
    "               'X_2787',\n",
    "               'X_1534',\n",
    "               'X_2041',\n",
    "               'X_1291',\n",
    "               'X_1242',\n",
    "               'X_1526',\n",
    "               'X_2753',\n",
    "               'X_1337',\n",
    "               'X_1338',\n",
    "               'X_1350',\n",
    "               'X_1341',\n",
    "               'X_2793',\n",
    "               'X_1552',\n",
    "               'X_1551',\n",
    "               'X_1421',\n",
    "               'X_1418',\n",
    "               'X_1349',\n",
    "               'X_2044',\n",
    "               'X_1353',\n",
    "               'X_1275',\n",
    "               'X_1297',\n",
    "               'X_2788',\n",
    "               'X_1358',\n",
    "               'X_1204',\n",
    "               'X_2771',\n",
    "               'X_1708',\n",
    "               'X_1076',\n",
    "               'X_2437',\n",
    "               'X_1554',\n",
    "               'X_1716',\n",
    "               'X_1429',\n",
    "               'X_2430',\n",
    "               'X_2782',\n",
    "               'X_1301',\n",
    "               'X_1422',\n",
    "               'X_1063',\n",
    "               'X_2412',\n",
    "               'X_2410',\n",
    "               'X_1083',\n",
    "               'X_379',\n",
    "               'X_1694',\n",
    "               'X_1114',\n",
    "               'X_350',\n",
    "               'X_354',\n",
    "               'X_1273',\n",
    "               'X_356',\n",
    "               'X_1118',\n",
    "               'X_1277',\n",
    "               'X_1278',\n",
    "               'X_1279',\n",
    "               'X_365',\n",
    "               'X_366',\n",
    "               'X_370',\n",
    "               'X_1097',\n",
    "               'X_1113',\n",
    "               'X_2750',\n",
    "               'X_1342',\n",
    "               'X_1107',\n",
    "               'X_1420',\n",
    "               'X_1288',\n",
    "               'X_1679',\n",
    "               'X_1104',\n",
    "               'X_1101',\n",
    "               'X_1686',\n",
    "               'X_1736',\n",
    "               'X_1051',\n",
    "               'X_2792',\n",
    "               'X_945',\n",
    "               'X_2078',\n",
    "               'X_939',\n",
    "               'X_1391',\n",
    "               'X_1388',\n",
    "               'X_2061',\n",
    "               'X_1821',\n",
    "               'X_1822',\n",
    "               'X_1383',\n",
    "               'X_984',\n",
    "               'X_982',\n",
    "               'X_981',\n",
    "               'X_1832',\n",
    "               'X_2794',\n",
    "               'X_1375',\n",
    "               'X_2843',\n",
    "               'X_1372',\n",
    "               'X_1339',\n",
    "               'X_1357',\n",
    "               'X_1355',\n",
    "               'X_1354',\n",
    "               'X_1346',\n",
    "               'X_1858',\n",
    "               'X_1345',\n",
    "               'X_1860',\n",
    "               'X_2058',\n",
    "               'X_2082',\n",
    "               'X_1000',\n",
    "               'X_1398',\n",
    "               'X_1419',\n",
    "               'X_1417',\n",
    "               'X_1416',\n",
    "               'X_1052',\n",
    "               'X_1748',\n",
    "               'X_1123',\n",
    "               'X_1415',\n",
    "               'X_1047',\n",
    "               'X_2800',\n",
    "               'X_2801',\n",
    "               'X_1757',\n",
    "               'X_1043',\n",
    "               'X_1042',\n",
    "               'X_2096',\n",
    "               'X_1036',\n",
    "               'X_1035',\n",
    "               'X_2047',\n",
    "               'X_1406',\n",
    "               'X_1026',\n",
    "               'X_1780',\n",
    "               'X_1019',\n",
    "               'X_1016',\n",
    "               'X_1002',\n",
    "               'X_1660',\n",
    "               'X_1344',\n",
    "               'X_1588',\n",
    "               'X_1171',\n",
    "               'X_2019',\n",
    "               'X_1185',\n",
    "               'X_1536',\n",
    "               'X_1217',\n",
    "               'X_1630',\n",
    "               'X_1246',\n",
    "               'X_1218',\n",
    "               'X_2701',\n",
    "               'X_1145',\n",
    "               'X_1174',\n",
    "               'X_306',\n",
    "               'X_1517',\n",
    "               'X_1148',\n",
    "               'X_2714',\n",
    "               'X_1963',\n",
    "               'X_1618',\n",
    "               'X_1617',\n",
    "               'X_1615',\n",
    "               'X_1170',\n",
    "               'X_265',\n",
    "               'X_1232',\n",
    "               'X_266',\n",
    "               'X_1156',\n",
    "               'X_1226',\n",
    "               'X_1225',\n",
    "               'X_1168',\n",
    "               'X_2020',\n",
    "               'X_1224',\n",
    "               'X_2715',\n",
    "               'X_1189',\n",
    "               'X_1190',\n",
    "               'X_142',\n",
    "               'X_1561',\n",
    "               'X_338',\n",
    "               'X_129',\n",
    "               'X_1657',\n",
    "               'X_344',\n",
    "               'X_2023',\n",
    "               'X_140',\n",
    "               'X_1553',\n",
    "               'X_1544',\n",
    "               'X_1646',\n",
    "               'X_138',\n",
    "               'X_1187',\n",
    "               'X_1133',\n",
    "               'X_1200',\n",
    "               'X_1188',\n",
    "               'X_2731']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(A_X, A_y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model_A = lgb.LGBMClassifier(random_state=42)\n",
    "    model_A.fit(X_train, y_train)\n",
    "    prediction = model_A.predict(X_test)\n",
    "\n",
    "    model_A.fit(X_train, y_train)\n",
    "    prediction = model_A.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(prediction, y_test))\n",
    "    print(f\"A_정답률:{accuracy_score(prediction, y_test):.3f}\")\n",
    "\n",
    "    return model_A, A_X.columns\n",
    "\n",
    "\n",
    "data_modeling_Aa()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "#\n",
    "# feat_labels = X_train.columns\n",
    "#\n",
    "# rf = RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = -1)\n",
    "#\n",
    "# rf.fit(X_train, y_train)\n",
    "# importances = rf.feature_importances_\n",
    "#\n",
    "# # argsort : 리스트 인덱스의 정렬됐을 때의 인덱스 값 반환, [::-1] : 뒤집기\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "#\n",
    "# for i in range(X_train.shape[1]):\n",
    "# \tprint(feat_labels[indices[i]], importances[indices[i]])\n",
    "#\n",
    "# #상위20개만...\n",
    "# # a=[]\n",
    "# # for i in range(80):\n",
    "# #     a.append(feat_labels[indices[i]])\n",
    "# # print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  1  0]\n",
      " [ 5 81 13]\n",
      " [ 0  1  0]]\n",
      "T_정답률:0.810\n",
      "['X_454', 'X_120', 'X_456', 'X_401', 'X_899', 'X_536', 'X_757', 'X_772', 'X_461', 'X_775', 'X_458', 'X_754', 'X_460', 'X_698', 'X_766', 'X_901', 'X_446', 'X_453', 'X_763', 'X_562', 'X_457', 'X_452', 'X_2', 'X_769', 'X_883', 'X_11', 'X_448', 'X_468', 'X_544', 'X_566', 'X_442', 'X_22', 'X_405', 'X_12', 'X_123', 'X_13', 'X_462', 'X_885', 'X_543', 'X_651', 'X_62', 'X_463', 'X_451', 'X_121', 'X_404', 'X_43', 'X_402', 'X_898', 'X_60', 'X_771', 'X_545', 'X_443', 'X_774', 'X_400', 'X_559', 'X_58', 'X_56', 'X_20', 'X_44', 'X_560', 'X_539', 'X_18', 'X_564', 'X_471', 'X_21', 'X_773', 'X_542', 'X_447', 'X_90', 'X_65', 'X_900', 'X_884', 'X_403', 'X_565', 'X_40', 'X_755', 'X_753', 'X_41', 'X_450', 'X_537', 'X_758', 'X_42', 'X_16', 'X_538', 'X_756', 'X_46', 'X_47']\n"
     ]
    },
    {
     "data": {
      "text/plain": "(LGBMClassifier(random_state=42),\n ['X_1',\n  'X_2',\n  'X_11',\n  'X_12',\n  'X_13',\n  'X_16',\n  'X_18',\n  'X_20',\n  'X_21',\n  'X_22',\n  'X_39',\n  'X_40',\n  'X_41',\n  'X_42',\n  'X_43',\n  'X_44',\n  'X_46',\n  'X_47',\n  'X_48',\n  'X_49',\n  'X_50',\n  'X_51',\n  'X_52',\n  'X_53',\n  'X_54',\n  'X_55',\n  'X_56',\n  'X_57',\n  'X_58',\n  'X_59',\n  'X_60',\n  'X_61',\n  'X_62',\n  'X_63',\n  'X_64',\n  'X_65',\n  'X_66',\n  'X_90',\n  'X_120',\n  'X_121',\n  'X_123',\n  'X_400',\n  'X_401',\n  'X_402',\n  'X_403',\n  'X_404',\n  'X_405',\n  'X_442',\n  'X_443',\n  'X_444',\n  'X_446',\n  'X_447',\n  'X_448',\n  'X_450',\n  'X_451',\n  'X_452',\n  'X_453',\n  'X_454',\n  'X_456',\n  'X_457',\n  'X_458',\n  'X_460',\n  'X_461',\n  'X_462',\n  'X_463',\n  'X_464',\n  'X_468',\n  'X_470',\n  'X_471',\n  'X_536',\n  'X_537',\n  'X_538',\n  'X_539',\n  'X_542',\n  'X_543',\n  'X_544',\n  'X_545',\n  'X_559',\n  'X_560',\n  'X_562',\n  'X_563',\n  'X_564',\n  'X_565',\n  'X_566',\n  'X_651',\n  'X_698',\n  'X_753',\n  'X_754',\n  'X_755',\n  'X_756',\n  'X_757',\n  'X_758',\n  'X_763',\n  'X_765',\n  'X_766',\n  'X_767',\n  'X_768',\n  'X_769',\n  'X_770',\n  'X_771',\n  'X_772',\n  'X_773',\n  'X_774',\n  'X_775',\n  'X_883',\n  'X_884',\n  'X_885',\n  'X_898',\n  'X_899',\n  'X_900',\n  'X_901'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seperate_code()\n",
    "\n",
    "\n",
    "def data_modeling_T():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "    data_T = df[(df[\"PRODUCT_CODE\"] == \"T_31\") | (df[\"PRODUCT_CODE\"] == \"O_31\")]\n",
    "\n",
    "    lists = []\n",
    "    for a in make_col()[2]:\n",
    "        lists.append(int(a[2:]))\n",
    "    lists.sort()\n",
    "\n",
    "    cols = []  # 사용할 columns\n",
    "    for l in lists:\n",
    "        cols.append(f\"X_{l}\")\n",
    "\n",
    "    T_y = data_T[\"Y_Class\"]\n",
    "    T_X = data_T[cols]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(T_X, T_y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model_T = lgb.LGBMClassifier(random_state=42)\n",
    "    model_T.fit(X_train, y_train)\n",
    "    prediction = model_T.predict(X_test)\n",
    "\n",
    "    #특성중요도 찾기\n",
    "    feat_labels = X_train.columns\n",
    "    importances = model_T.feature_importances_\n",
    "\n",
    "    # argsort : 리스트 인덱스의 정렬됐을 때의 인덱스 값 반환, [::-1] : 뒤집기\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    a = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        if importances[indices[i]] > 1:\n",
    "            a.append(feat_labels[indices[i]])\n",
    "\n",
    "    print(confusion_matrix(prediction, y_test))\n",
    "    print(f\"T_정답률:{accuracy_score(prediction, y_test):.3f}\")\n",
    "    print(a)\n",
    "    return model_T, cols\n",
    "\n",
    "\n",
    "data_modeling_T()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seperate_code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/js/792bsrvx24lcg4nrdgy7k5br0000gn/T/ipykernel_15535/815291917.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensemble\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mRandomForestClassifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mseperate_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'seperate_code' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seperate_code()\n",
    "\n",
    "\n",
    "def data_modeling_T():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "    data_T = df[(df[\"PRODUCT_CODE\"] == \"T_31\") | (df[\"PRODUCT_CODE\"] == \"O_31\")]\n",
    "\n",
    "    lists = []\n",
    "    for a in make_col()[2]:\n",
    "        lists.append(int(a[2:]))\n",
    "    lists.sort()\n",
    "\n",
    "    cols = []  # 사용할 columns\n",
    "    for l in lists:\n",
    "        cols.append(f\"X_{l}\")\n",
    "\n",
    "    T_y = data_T[\"Y_Class\"]\n",
    "    T_X = data_T[cols]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(T_X, T_y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model_T = lgb.LGBMClassifier(random_state=42)\n",
    "    model_T.fit(X_train, y_train)\n",
    "    prediction = model_T.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(prediction, y_test))\n",
    "    print(f\"T_정답률:{accuracy_score(prediction, y_test):.3f}\")\n",
    "\n",
    "    return model_T, cols\n",
    "\n",
    "\n",
    "data_modeling_T()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 이거는 초기 데이터 안지우고 해보는거임...\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seperate_code()\n",
    "\n",
    "def data_modeling_T():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'train.csv')\n",
    "    data_T = df[(df[\"PRODUCT_CODE\"] == \"T_31\") | (df[\"PRODUCT_CODE\"] == \"O_31\")]\n",
    "\n",
    "    lists = []\n",
    "    for a in make_col()[2]:\n",
    "        lists.append(int(a[2:]))\n",
    "    lists.sort()\n",
    "\n",
    "    cols = []  # 사용할 columns\n",
    "    for l in lists:\n",
    "        cols.append(f\"X_{l}\")\n",
    "\n",
    "    T_y = data_T[\"Y_Class\"]\n",
    "    T_X = data_T.drop([\"Y_Class\", \"Y_Quality\"], axis=1).select_dtypes(exclude=['object'])\n",
    "    # T_X = data_T[['X_454', 'X_120', 'X_456', 'X_401', 'X_899', 'X_536', 'X_757', 'X_772', 'X_461', 'X_775', 'X_458', 'X_754', 'X_460', 'X_698', 'X_766', 'X_901', 'X_446', 'X_453', 'X_763', 'X_562', 'X_457', 'X_452', 'X_2', 'X_769', 'X_883', 'X_11', 'X_448', 'X_468', 'X_544', 'X_566', 'X_442', 'X_22', 'X_405', 'X_12', 'X_123', 'X_13', 'X_462', 'X_885', 'X_543', 'X_651', 'X_62', 'X_463', 'X_451', 'X_121', 'X_404', 'X_43', 'X_402', 'X_898', 'X_60', 'X_771', 'X_545', 'X_443', 'X_774', 'X_400', 'X_559', 'X_58', 'X_56', 'X_20', 'X_44', 'X_560', 'X_539', 'X_18', 'X_564', 'X_471', 'X_21', 'X_773', 'X_542', 'X_447', 'X_90', 'X_65', 'X_900', 'X_884', 'X_403', 'X_565', 'X_40', 'X_755', 'X_753', 'X_41', 'X_450', 'X_537', 'X_758', 'X_42', 'X_16', 'X_538', 'X_756', 'X_46', 'X_47']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(T_X, T_y, test_size=0.3, random_state=42)\n",
    "\n",
    "    model_T = lgb.LGBMClassifier(random_state=42)\n",
    "    model_T.fit(X_train, y_train)\n",
    "    prediction = model_T.predict(X_test)\n",
    "\n",
    "    #특성중요도 찾기\n",
    "    feat_labels = X_train.columns\n",
    "    importances = model_T.feature_importances_\n",
    "\n",
    "    # argsort : 리스트 인덱스의 정렬됐을 때의 인덱스 값 반환, [::-1] : 뒤집기\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    a = []\n",
    "    for i in range(X_train.shape[1]):\n",
    "        if importances[indices[i]] > 1:\n",
    "            a.append(feat_labels[indices[i]])\n",
    "            print(feat_labels[indices[i]], )\n",
    "\n",
    "    print(confusion_matrix(prediction, y_test))\n",
    "    print(f\"T_정답률:{accuracy_score(prediction, y_test):.3f}\")\n",
    "    print(a)\n",
    "\n",
    "\n",
    "    return model_T, cols\n",
    "\n",
    "data_modeling_T()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def predict_testset():\n",
    "    data_path = '/Users/sola/Downloads/open/'\n",
    "    df = pd.read_csv(data_path + 'test.csv')\n",
    "\n",
    "    data_A = data_modeling_A()\n",
    "    data_T = data_modeling_T()\n",
    "\n",
    "    # A_testset\n",
    "    df_A = df[df[\"PRODUCT_CODE\"] == \"A_31\"]\n",
    "\n",
    "    df_test_A = pd.DataFrame()\n",
    "    A_cols = data_A[1]\n",
    "\n",
    "    for c, col in enumerate(A_cols):\n",
    "        df_test_A[col] = df_A[col]\n",
    "\n",
    "    # T_testset\n",
    "    df_T = df[(df[\"PRODUCT_CODE\"] == \"T_31\") | (df[\"PRODUCT_CODE\"] == \"O_31\")]\n",
    "\n",
    "    df_test_T = pd.DataFrame()\n",
    "    T_cols = data_T[1]\n",
    "\n",
    "    for c, col in enumerate(T_cols):\n",
    "        df_test_T[col] = df_T[col]\n",
    "\n",
    "    pred_A = data_A[0].predict(df_test_A)\n",
    "    pred_T = data_T[0].predict(df_test_T)\n",
    "\n",
    "    # Code A, T 순서 원래대로 변경\n",
    "    A_index = df[df[\"PRODUCT_CODE\"] == \"A_31\"].index\n",
    "    T_index = df[(df[\"PRODUCT_CODE\"] == \"T_31\") | (df[\"PRODUCT_CODE\"] == \"O_31\")].index\n",
    "\n",
    "    A_add_df = pd.DataFrame()\n",
    "    A_add_df[\"index\"] = A_index\n",
    "    A_add_df[\"predict\"] = pred_A\n",
    "\n",
    "    T_add_df = pd.DataFrame()\n",
    "    T_add_df[\"index\"] = T_index\n",
    "    T_add_df[\"predict\"] = pred_T\n",
    "\n",
    "    predict_data = pd.concat([A_add_df, T_add_df])\n",
    "    predict_data = predict_data.sort_values(by=[\"index\"], ascending=[True])\n",
    "\n",
    "    # submit\n",
    "    output_dir = \"Result/\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    submit = pd.read_csv(data_path + 'sample_submission.csv')\n",
    "    submit[\"Y_Class\"] = predict_data[\"predict\"].values\n",
    "    submit.to_csv(os.path.join(output_dir, \"./sola_submission1.csv\"), index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/js/792bsrvx24lcg4nrdgy7k5br0000gn/T/ipykernel_2310/3201508995.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mseperate_code\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# predict_testset()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mpredict_testset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/js/792bsrvx24lcg4nrdgy7k5br0000gn/T/ipykernel_2310/636068646.py\u001B[0m in \u001B[0;36mpredict_testset\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'test.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mdata_A\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_modeling_A\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mdata_T\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_modeling_T\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/js/792bsrvx24lcg4nrdgy7k5br0000gn/T/ipykernel_2310/3990626102.py\u001B[0m in \u001B[0;36mdata_modeling_A\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mmodel_A\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomForestClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_estimators\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     \u001B[0mmodel_A\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m     \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_A\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    325\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    326\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 327\u001B[0;31m         X, y = self._validate_data(\n\u001B[0m\u001B[1;32m    328\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    329\u001B[0m         )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    579\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 581\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    582\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    583\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    962\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"y cannot be None\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    963\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 964\u001B[0;31m     X = check_array(\n\u001B[0m\u001B[1;32m    965\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    966\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    798\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    799\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 800\u001B[0;31m             \u001B[0m_assert_all_finite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_nan\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"allow-nan\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    801\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    802\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mensure_min_samples\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[1;32m    112\u001B[0m         ):\n\u001B[1;32m    113\u001B[0m             \u001B[0mtype_err\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"infinity\"\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mallow_nan\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"NaN, infinity\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m    115\u001B[0m                 msg_err.format(\n\u001B[1;32m    116\u001B[0m                     \u001B[0mtype_err\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "seperate_code()\n",
    "# predict_testset()\n",
    "predict_testset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
